# 로봇 하드웨어 조립 후 작업 가이드 (v0.16 기준)

이 문서는 모터와 바퀴 등 모든 하드웨어 조립이 완료된 후, 실제 로봇의 구동을 테스트하고 SLAM 및 내비게이션을 실행하기 위한 소프트웨어 설정 및 실행 방법을 안내합니다.

## 1. 필수 준비 사항

로봇을 구동하기 전에 다음 준비가 반드시 완료되어야 합니다.

*   **하드웨어 조립**: 라즈베리파이, OpenCR 보드, Dynamixel XL-430 모터 (4개), 바퀴, 라이다, 카메라 등 모든 하드웨어가 물리적으로 조립되고 연결된 상태여야 합니다.
*   **OpenCR 펌웨어 업로드**: **가장 중요한 단계입니다.** OpenCR 보드에 `turtlebot3_core.ino` 펌웨어를 업로드해야 합니다. 이 펌웨어는 OpenCR 보드가 ROS2와 통신할 수 있도록 해주는 핵심 소프트웨어입니다.
    *   **주의:** 펌웨어 코드에서 통신 속도(Baudrate)가 **1000000**으로 설정되어 있는지 확인해야 합니다. 이는 우리 런치 파일의 `slampibot.yaml` 설정과 일치해야 합니다.
*   **네트워크 설정**: 로봇의 라즈베리파이와 로봇을 제어할 원격 PC가 동일한 네트워크에 연결되어 있어야 합니다.

## 2. 라즈베리파이 소프트웨어 설정

1.  **ROS2 및 관련 패키지 설치**: 라즈베리파이에 ROS2 Humble, `turtlebot3_node`, `rplidar_ros` 등 필요한 모든 패키지가 설치되어 있어야 합니다.
2.  **워크스페이스 클론 및 빌드**: 이 프로젝트(`slampibot_gazebo`)를 라즈베리파이의 ROS2 워크스페이스(`ros2_ws/src`)에 클론하고, `colcon build` 명령으로 전체 워크스페이스를 빌드합니다.
    ```bash
    cd ~/ros2_ws
    colcon build
    ```

## 2.5. (중요) 천장 카메라 캘리브레이션

천장 카메라를 이용한 위치 추정 및 장애물 인식을 위해서는 카메라 캘리브레이션이 **반드시** 선행되어야 합니다. 이 과정은 렌즈의 왜곡을 보정하고 카메라의 내부 파라미터를 측정하여, 이미지의 픽셀 좌표를 실제 3D 공간 좌표로 정확하게 변환하기 위해 필요합니다.

#### 1단계: 필요 패키지 설치

ROS2의 표준 카메라 캘리브레이션 도구를 설치합니다.

```bash
sudo apt update
sudo apt install ros-humble-camera-calibration ros-humble-usb-cam
```
*(위 명령어는 `usb_cam` 패키지를 사용하는 것을 가정합니다. 만약 다른 카메라 드라이버를 사용하신다면 해당 드라이버만 설치되어 있으면 됩니다.)*

#### 2단계: 체커보드 준비

1.  **체커보드 인쇄:** [여기](https://raw.githubusercontent.com/ros-perception/camera_calibration/rolling/doc/images/checkerboard_8x6.png)와 같은 8x6 크기의 체커보드 이미지를 다운로드하여 A4 용지 등에 왜곡 없이 인쇄합니다.
2.  **평평한 판에 부착:** 인쇄한 체커보드를 구겨지지 않도록 평평하고 단단한 판(하드보드지, 아크릴판 등)에 붙입니다.
3.  **정사각형 한 변 길이 측정:** **매우 중요한 단계입니다.** 체커보드에 있는 **검은색 또는 흰색 정사각형의 한 변의 길이를 자로 매우 정밀하게 측정**합니다. 이 값을 **미터(m) 단위**로 기록해 둡니다. (예: 2.5cm → 0.025m)

#### 3단계: 카메라 노드 실행

캘리브레이션을 진행할 천장 카메라의 드라이버 노드를 실행하여 이미지 토픽을 발행시킵니다.

```bash
# 아래는 usb_cam 패키지를 사용하는 예시입니다.
# 사용하는 카메라에 맞는 런치 파일 또는 노드를 실행하세요.
ros2 launch usb_cam camera.launch.py
```
*실행 후 `ros2 topic list` 명령으로 카메라의 이미지 토픽 이름(예: `/image_raw`)을 확인합니다.*

#### 4단계: 캘리브레이션 노드 실행

새로운 터미널을 열고 아래 명령어를 실행하여 캘리브레이션 도구를 시작합니다. **`--size`, `--square`, `image:=...` 부분은 사용자의 환경에 맞게 수정해야 합니다.**

```bash
# 예시 명령어
ros2 run camera_calibration cameracalibrator \
--size 8x6 \
--square 0.025 \
image:=/image_raw
```

*   `--size 8x6`: 체커보드 내부 코너의 개수입니다. (가로 8개, 세로 6개)
*   `--square 0.025`: 2단계에서 측정한 정사각형 한 변의 길이(미터 단위)입니다.
*   `image:=/image_raw`: 3단계에서 확인한 카메라의 이미지 토픽 이름입니다.

#### 5단계: 캘리브레이션 진행

*   명령을 실행하면 "Camera Calibrator"라는 창이 나타납니다.
*   체커보드 판을 들고 천장 카메라에 잘 보이도록 여러 각도, 여러 위치, 여러 거리에서 천천히 움직여 줍니다.
*   체커보드가 인식되면 창에 녹색 선들이 표시됩니다. 창 오른쪽의 `X`, `Y`, `Size`, `Skew` 막대가 최대한 많이 채워지도록 다양한 구도에서 체커보드를 보여줍니다.
*   막대가 충분히 채워지면, 창 우측 상단의 **`CALIBRATE`** 버튼이 활성화됩니다. 이 버튼을 클릭합니다.
*   잠시 계산 과정이 진행된 후, 왜곡이 보정된 이미지가 창에 나타납니다.

#### 6단계: 결과 저장

*   캘리브레이션 계산이 성공적으로 끝나면, `CALIBRATE` 버튼이 있던 자리에 **`SAVE`** 버튼이 활성화됩니다.
*   `SAVE` 버튼을 클릭하면, 캘리브레이션 결과가 담긴 `.yaml` 파일이 생성되고, 터미널에 저장된 경로(보통 `/tmp/calibration.yaml` 또는 `/tmp/calibrationdata.tar.gz` 안)가 표시됩니다.

#### 7단계: 캘리브레이션 파일 적용

1.  6단계에서 생성된 `.yaml` 파일을 프로젝트의 `config` 폴더와 같이 찾기 쉬운 곳으로 복사합니다.
2.  카메라를 실행하는 런치 파일을 수정하여, `camera_info_url` 파라미터를 통해 이 캘리브레이션 파일을 사용하도록 지정합니다.

**런치 파일 수정 예시:**
```python
# ... (런치 파일의 다른 부분)
Node(
    package='usb_cam',
    executable='camera_node', # 사용하는 카메라 노드에 맞게 수정
    name='ceiling_camera',
    parameters=[
        {'camera_info_url': 'file:///home/kkit/programming/ROS2/Ros_ws_book/src/map_table_publisher/config/calibration.yaml'}
    ],
    remappings=[('image_raw', '/ceiling_camera/image_raw')]
)
# ...
```

## 3. 실행 및 테스트 가이드

모든 준비가 완료되면, 다음 단계에 따라 기능을 테스트할 수 있습니다. 각 런치 파일은 로봇(라즈베리파이)에서 실행합니다. RViz나 `rqt_robot_steering`과 같은 GUI 도구는 원격 PC에서 실행하여 로봇을 제어하고 모니터링합니다.

### 1단계: 기본 동작 및 키보드 조종 테스트

*   **목적**: 모터가 정상적으로 작동하는지, 로봇이 의도한 대로 움직이는지 확인하는 초기 하드웨어 테스트입니다.
*   **실행 명령어 (라즈베리파이 터미널):**
    ```bash
    source ~/ros2_ws/install/setup.bash
    ros2 launch slampibot_gazebo real_robot.launch.py
    ```
*   **예상 결과**:
    *   명령 실행 시, **새로운 터미널 창이 나타나며** 키보드 조종 노드(`teleop_keyboard`)가 실행됩니다.
    *   해당 터미널 창에서 `w, a, s, d, x` 키를 사용하여 로봇을 직접 제어할 수 있습니다.
    *   로봇이 키보드 입력에 따라 정상적으로 움직인다면, `turtlebot3_node`와 OpenCR 펌웨어 간의 통신이 성공적으로 이루어진 것입니다.
    *   (원격 PC) `rviz2`를 실행하여 로봇 모델이 올바르게 표시되는지, TF가 정상적으로 발행되는지 확인할 수 있습니다.

### 2단계: SLAM (지도 생성)

*   **목적**: 로봇을 조종하여 주변 환경의 지도를 생성하고 저장합니다.
*   **실행 명령어 (라즈베리파이 터미널):**
    ```bash
    source ~/ros2_ws/install/setup.bash
    ros2 launch slampibot_gazebo real_cartographer.launch.py
    ```
*   **작업 순서**:
    1.  위 명령어로 SLAM 관련 노드들을 모두 실행합니다.
    2.  **원격 PC**에서 `rqt_robot_steering`을 실행하여 로봇을 부드럽게 조종하며 지도 영역을 탐색합니다.
        ```bash
        rqt_robot_steering
        ```
    3.  **원격 PC**에서 `rviz2`를 실행하고, `/map` 토픽을 추가하여 실시간으로 지도가 만들어지는 과정을 확인합니다.
    4.  지도가 완성되면, **원격 PC의 새 터미널**에서 아래 명령어를 실행하여 지도를 저장합니다. (`~/map`은 원하는 경로와 파일 이름으로 변경 가능)
        ```bash
        ros2 run nav2_map_server map_saver_cli -f ~/map
        ```

### 3단계: 내비게이션 (자율 주행)

*   **목적**: 2단계에서 생성하고 저장한 지도를 이용해 로봇이 자율적으로 목표 지점까지 주행하도록 합니다.
*   **사전 준비**: `maps` 폴더에 `spb_map.yaml`과 `spb_map.pgm` 파일이 저장되어 있어야 합니다. (이름이 다르다면 `real_nav.launch.py` 파일 수정 필요)
*   **실행 명령어 (라즈베리파이 터미널):**
    ```bash
    source ~/ros2_ws/install/setup.bash
    ros2 launch slampibot_gazebo real_nav.launch.py
    ```
*   **작업 순서**:
    1.  위 명령어로 내비게이션 스택을 포함한 모든 노드를 실행합니다.
    2.  **원격 PC**에서 `rviz2`를 실행합니다. 로봇이 지도 상에 나타나고, 라이다 센서 데이터가 지도와 일치하는 것을 확인합니다.
    3.  RViz의 `2D Pose Estimate` 툴을 사용하여 로봇의 현재 위치와 방향을 지도 상에 지정해줍니다. (초기 위치 추정)
    4.  RViz의 `Nav2 Goal` 툴을 사용하여 목표 지점을 클릭하면, 로봇이 해당 지점까지 자율적으로 경로를 계획하고 주행합니다.
    5.  `waypoint_commander_node`가 함께 실행되므로, 웹 인터페이스를 통한 웨이포인트 주행도 테스트할 수 있습니다.
